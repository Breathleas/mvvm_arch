## 编译器

    主流的三段式编译器架构：
        第一段--前端（Frontend）：
            工作集中在词法分析、语法分析、语义分析以及中间表示生成
            工具有 lex、yacc等
            输入为源代码，输出为中间表示（Intermediate Representation，IR 被称为中间代码、中间语言，Java字节码也是一种IR）
        第二段--优化器：
            优化原理
            输入是未优化的IR，输出优化后的IR
            优化手段有 循环优化、常量传播和折叠、无用代码消除、方法内联优化等
            优化阶段的最后考虑如何分配物理寄存器、内存
        第三段--后端（Backend）：
            机器码生成
            输入优化后的IR，输出目标机器的机器码
            主要功能是将IR 翻译成机器码（Code Generator）
    两段式编译器架构中，Backend 包括优化器和代码生成器
    三段式更具有可扩展性
    Frontend -> 优化器 -> Backend
    可针对每段独立开发
    LLVM ：只是一个编译器基础架构和编译器开发库，不是一个完整的编译器（不包括Frontend），可搭配针对
        不同语言的前端就可以构造相应的编译器，Clang搭配LLVM构成C/C++编译器，也可以搭配GCC使用。
    GCC ：三段耦合大
    

#### 前端介绍
    
        前端依次包括词法分析、语法分析、语义分析以及中间表示生成（IR生成）等
        词法分析（Lexical Analysis），Token，正则表达式
        语法分析（Syntax Analysis）：根据特定编程语言的文法规则对输入的Token流进行分析
        语义分析（）：对源码进行检查，类型检查、语法相关性检查、一致性检查等，也叫上下文相关分析（Context Sensitive Analysis）
        IR分为 高级（High IR，用的比较少）、中级（Middle IR，用的比较普遍，比如 LLVM IR）、低级（Low IR，用的比较少）IR
        
      
##### 词法分析和 lex
    
        词法分析的目标是识别输入字符流中的特定单词，用到的基础技术就是正则表达式
        最长字符串匹配规则
        lex工具（Unix平台）：
            将输入的lex规则文件转换成对应的C代码，编译C代码就可得到一个能对输入的字符串按照指定规则（lex规则文件中指定）进行词法分析的可执行程序
            lex规则文件-->lex-->lex.yy.c(默认)-->gcc(g++/clang等)-->可执行文件
        lex规则文件：
            定义段（definition section）：
                为复杂正则表达式定义一个别名（类似C的宏定义），以便在规则段中使用；
                可包含一些需要原封不动输出到源码文件中的内容（包含在%{%}中）
                可以没有定义段
            规则段（rules section）：
                定义段和规则段之间通过 %% 符号隔开，不管有么有定义段， %% 符号必须存在
                描述输入字符串匹配正则表达式时执行什么 action
                action 可以是一段C/C++代码，也可以是lex定义的某个动作（lex定义的几个宏）
            用户子程序段（user subroutines section）：
                lex生成源码时，会原封不动地将该段中的内容拷贝到输出的源码文件中，此段内容一般是C代码
                该段不是必须存在的，若没有该段内容，最后一个 %% 符号不需要
        
        lex规则：
            一条规则包含左右两部分：左部是该规则对应的正则表达式，右部是该正则表达式对应的动作，之间通过空格或TAB隔开
            正则表达式（Regular Expression）：
                用于描述字符串匹配模式的方法，由普通字符或特殊字符（元字符）组成
                "" ：双引号内部的字符必须逐一匹配（包括元字符，区分大小写），eg："abc+" 匹配字符串 “abc+”
                .  ：匹配任意字符（除换行符 \n），要匹配本身，使用 \. 或 "."
                [] ：表示可匹配字符的取值范围，取反符^ 表示不使用方括号中列出的字符，连字符- 表示一个连续的字符取值范围，-只能出现在[]中，
                    ^在方括号中只能为第一个字符，eg：[AxgB] 匹配任意一个字符，[^AxgB] 表示字符串中不能有其中任意一个字符，[a-ZA-Z0-9] 字母数字任一字符，[^a-zA-Z0-9] 非字母数字
                ?+*：? 0或1个重复，+ 1个及以上的重复，* 0个或多个重复，eg：ab? 为 a, ab，ab+ 为 ab,abb等，ab* 为 a,ab,abb等
                {} ：其中不是数字，则是对RE别名的引用，包含数字，表示对应字符匹配的精确重复次数
                    eg：{I} I为正则表达式别名； A{1,3} 表示 A重复一次或者3次 （A或AAA）？
                $^ ：$ 在RE的最后，表示结尾， ^ 在RE开头，表示以某字符开头，eg：abc$ abc在字符串结尾，^abc 字符串以abc开头
                |()：| 逻辑或，用于组合多个RE，匹配其中一个RE即可，() 用于将RE进行分组， (RE1|RE2)RE3 表示要么 RE1RE3，要么 RE2RE3
                \  ：转义字符，对元字符转义
                /  ：前向匹配符，  ab/[cd]，表示ab 后面必须跟 c 或 d 才能匹配，输出是 / 前的ab
            规则书写：
                RE1     action1
                RE2     |
                RE3     |
                RE4     action2     <==使用 | 连接多个RE，共用一个action
            lex常用变量和函数：
                与lex词法分析核心库做交互
                yytext      类型为 char*，取值为 RE匹配的字符串
                yylength    代表 yytext 的长度
                yyin、yyout  类型为 FILE*，输入和输出流，默认指向标准输入输出，可修改为指向文件等
                yylex函数     词法分析的核心函数，yylex从yyin读入数据进行分析，结果输出到yyout
                yywrap函数    返回1 表示输入数据读取完毕，返回0 表示整个词法分析任务结束
                REJECT、ECHO     宏，在action中拒绝匹配某个RE，这时使用REJECT 指示lex继续搜索其余匹配项，ECHO用于输出匹配的字符串
                
                
##### 语法分析和 yacc
    
    yet another compiler compiler，是Unix平台上的一个工具程序
    可将语法规则文件转换成 C源码文件，编译此源文件后得到一个用于语法分析的程序
    语法分析要使用此法分析的结果，所以 yacc与lex 搭配使用
    流程：
        语法规则文件-->yacc-->y.tab.c、y.tab.h(默认)--(liby.a、词法分析结果)-->gcc(g++/clang等)-->可执行文件
        liby.a 为yacc 提供的静态库
    
    文法介绍
        语法分析的目的是判断语句是否符合语言规定的语法要求
        语法分析的首要任务是制定相应的语法规则
        语法规则是通过文法来描述的
        文法（Grammar）是一种用于描述语言的语法结构的形式规则
        任何一种语言都有对应的文法（编程语言、自然语言等）
        文法描述方法，最常用的一种是 BNF范式（Backus-Naur Form）
        示例：
            句子      ->      子句子 宾语
        一行就是一个产生式（production），表示箭头左边的内容由右边的内容组成，注意次序（-> 可由 ::= 替代）
        非终结符（nonterminal）：句子、宾语等    终结符（terminal）：你我他、吃喝等
        非终结符（nonterminal）：变量（可被赋值）  终结符（terminal）：基本符号（不能再对其进行分割）
        完整的文法中一定有唯一的文法开始符（start symbol），语法分析从文法开始符（非终结符）出发，然后通过推导或规约等方法逐步展开
        分析方法：
            1、自顶向下的推导（derivation）法
            2、自底向上的归约（derivation）法
        语法树（syntax tree）：
            使用树形结构来描述整个推导过程
            根节点是文法开始符
            将产生式右边的终结符或非终结符作为语法树的子节点
            最终推导完成（叶节点无非终结符）后，从左至右遍历该树的所有叶节点得到最后推导出来的句子
            最右推导：每次选择产生式里最右边的非终结符进行推导
            最左推导：每次选择产生式里最左边的非终结符进行推导
            选择产生式的方法：LL(1)法
        归约：
            归约是推导的逆过程
            从输入的句子开始，直到能得到文法开始符为止
            归约就是将产生式右边的部分替换为产生式左边的部分
            归约法最常用的数据结构是栈
            可归约的元素叫句柄（handle）
            选择产生式的方法：LR(1)法
            在规则文件中：
                定义段：
                    %token 定义终结符
                    %start 定义文法开始符
                    %{...%} 同lex
                    yyerror函数 yacc提供的，当语法分析错误时被调用
                    其他同lex规则文件一样
                规则段：
                    A   :   B {action for B}
                            C {action for C}
                          | D {action for D}
                          ;
                    范式中 -> 被 : 替代
                    ; 代表一个产生式的结束
                用户子程序段：
                    void yyerror(const char *s){...}
                    语法分析出错时，yyerror将被调用
        借助 lex 和 yacc，编写lex词法规则文件和yacc语法规则文件即可开发一个功能强大的词法或语法分析程序
        yacc使用归约法
        新的编程语言，对其进行词法、语法分析
    

##### 语义分析和IR生成

    语义分析
        语法制导转换（syntax directed translation），在文法产生式中设置一些动作，这些动作开展语义分析或采集信息为后续某动作对应的语义分析做准备
        语义分析也叫上下文相关分析，即分析当前代码时需要结合前面某行代码的信息，这些信息统一存储在 符号表
        静态语义检查（static semantic check），C/C++
        动态语义检查（dynamic semantic check），Java支持，检查数组越界等
    
    IR生成
        逻辑形式：单地址、二地址以及三地址
        Java字节码是一种单地址的IR
        IR生成在语法分析中设置对应的action完成的
        源代码翻译成IR包括对语句和表达式的翻译，其中还涉及类型系统、对函数调用的抽象（函数调用时的传参、返回值等）等内容
        

#### 优化器
    
    优化必须是安全的，优化不能改变原程序的语义
    程序的本质就是数据和控制
    控制流（control flow）：
        描述程序结构的相关信息
        优化器针对控制流的工作有：建立控制流图（Control flow Graph，CFG），循环结构分析等
    数据流（data flow）：
        描述程序数据的相关信息
        数据流峰分析依赖CFG
    编译器编译优化时先进行控制流和数据流分析，构造相关数据结构，收集必要信息，甚至对IR做一些变换和调整
    ART编译优化器输入是 dex字节码，输出是优化后的 HInstruction
    
##### 控制流 CFG：
    
    构造CFG：
        控制流分析需要先构造控制流图，其数据结构为 图，包含两部分：
            1、基本块（Basic Block）：
                基本块包含一行或多行代码，这些代码没有分支或跳转语句
                基本块内的代码从上到下的顺序执行
                分支或跳转前的代码分别放在不同的基本块中
                基本块相当于图的结点（node）
            2、边（edge）：
                基本块之间是有跳转关系的，跳转关系由边表示
                边是有方向的，代表从一个基本块跳转到另一个基本块
        CFG中的每一个基本块可以有N个边指向它，也可以有多个边出来，入边和出边的个数叫入度和出度
        CFG是针对函数构造的，函数最开始的语句构成一个入口基本块（Entry Basic Block），也可以构造一个空基本块作为入口基本块
        入口基本块的入度为0
        CFG只有一个出口基本块（Exit Basic Block），对于多个return语句，构造一个空基本块，return基本块指向空基本块，将该空基本块设为出口基本块
        出口基本块的出度为1
        入度为0的基本块除了入口基本块外，就是不会被执行的基本块，该基本块对应的代码可以去掉
        art中构造CFG相关类有 HGraph、HBasicBlock、HBasicBlockBuilder（源码地址：http://androidxref.com/9.0.0_r3/xref/art/compiler/optimizing/）
        art分析字节码，建立基本块之间的前驱-后继关系，根据抛异常等构造CFG
    
    分析和处理CFG：
        Dominator Tree：
            支配树（DT），由CFG构造出DT
            结点（node）x支配（dominator）结点y：x dom y（x是y的必经结点），若x!=y，则x strictly dom y，简写为 x sdom y
            直接支配结点（immediate dominator）：a,b dom c，但a 离c 最近，则a 被称为 c的直接支配结点，记为 a idom c
            后序支配结点（post dominator）：从END出发，调转各节点指向关系得到Post DT，c post-dominate a，记为 c pdom a
            支配边界（Dominator Frontier）：DF(x)={y|x dom pred(y) && x !sdom y}
        back edge和 natural loop：
            从后继结点指向前驱结点的边被称作 back edge（虚线），有back edge就表示该CFG里有 loop
            一个循环有一个入口结点，即loop 外的结点只能通过这个入口结点进入此loop，该入口结点被称为 loop的头（header）
            若有多条入边指向loop header，这种情况不利于对循环的优化，故构造一个preheader，将原来指向loop header的结点指向preheader，从而loop header只有一条入边
            preheader对优化的意义在于可以将一些循环不变量对应的计算放到preheader基本块中，消除冗余操作
            Natural Loop（自然循环）是优化器重点考察对象
            Natural Loop：c->a 为 back edge，同时满足 a dom c
            Natural Loop 表示外界只能通过loop header进入该loop，非natural loop表示外界有多个结点进入循环体
            reducible CFG：CFG里的loop全部是natural loop，该CFG可通过一系列变换归约为一个结点
        critical edge：
            a->b，改边的源结点a有多个后继结点，同时该边的目标结点有多个前驱结点，为 critical edge
            如果有 critical edge，优化器会认为此处存在潜在的优化空间，为此 CFG会拆分 critical edge
        CFG的遍历：
            对有向图的遍历，有广度优先搜索法（Breadth First Search，BFS）和深度优先搜索法（Depth First Search，DFS）
            CFG 采用 DFS
            前序遍历
            后序遍历
            逆后序遍历
            构造支配树，遍历edge，简化循环，简化CFG，拆分critical edge等的art源码（http://androidxref.com/9.0.0_r3/xref/art/compiler/optimizing/nodes.cc）
            
##### 数据流分析与 SSA
    
    数据流分析（data flow analysis）的是数据在程序里沿着程序执行路径流动及变化的情况
    数据流分析得到的信息对优化器后续开展诸如常量传播（Constant Propagation）、公共子表达式消除（Common subexpression elimination）、
      死代码消除（Dead code elimination）等优化工作非常有价值
    数据流分析经典方法：迭代数据流分析、基于控制树的数据流分析等
    ART优化器使用的是将IR转换成静态单赋值形式（Static Single Assignment Form），通过对IR进行一些处理使得数据流分析工作大大简化，还能有效改善后续优化工作的执行效率
    
    数据流分析
        两种分析手段--到达定值分析和活跃变量分析
        到达定值分析
            Reaching Definition Analysis，代码中某处使用了一个变量，这个变量的值来自于之前何处的定义？
            定值点（Definition）：变量x的定值点是一句IR，执行该IR会影响变量x的值（最常见的定值点是对x的赋值语句）
            引用点（Use）：变量x的引用点也是一句IR，该IR会使用变量x的值
            引用-定值链（ud chain）：点u引用变量x的值，则把能达到u的x的所有定值点的集合称为变量x能到达u引用点的引用-定值链，ud链关注的是x的某个引用点中，x的值可能会来自哪些定值点
            定值-引用链（du chain）：点d是变量x的定值点，则把该定值能达到的对x的所有引用点的集合称为变量x的d定值点的定值-引用链，du链关注的是某次对x的修改可能会影响哪些使用x的地方
            定值点d对应的变量x在某条路径上某个位置被赋值或修改，则称定值点d被杀死（killed）
            定值点、引用点均是指程序中的IR
            基本块内部定值点表示：GEN[d:y<-f(x,...)]={d}
            GEN存储了定值点，f是某种操作（x等为输入参数），该操作的结果返回给y，对于这种修改了y的值的IR就放到GEN集合
            GEN集合存储的是定值语句的编号
            基本块内部被杀死的定值点表示：KILL[d:y<-f(x,...)]=DEFS[y]-{d}
            DEFS[y]表示所有y的定值点
            KILL将它们都杀死，唯独保留自己的IR编号，如：KILL[B]={d1,d2,d3}-{d3}={d1,d2}
            基本块的IN和OUT集合：
                基本块B的IN是其所有前驱基本块OUT集合的并集
                基本块的OUT是GEN[B]和IN[B]-KILL[B]结果的并集
        活跃变量分析
            Live Variable Analysis，也叫活性分析（liveness analysis），程序中有一个变量x，变量x在后续代码里会不会被用到？
            活跃变量分析考察的是变量，到达定值分析是点
            GEN[d:y<-f(x1,...)]={x1,x2,...}
            KILL[d:y<-f(x1,...)]={y}
            GEN集合描述的是某行代码里引用的变量，x是变量
            KILL集合描述的是被修改的变量
            IN
            OUT
    
    SSA介绍
        静态单赋值（Static Single Assignment）
        IR 经改造可得SSA形式的IR（SSA Form IR）
        PHI函数，多版本变量选择时的中间变量
        代码优化完毕后需要去除PHI函数，即 SSA deconstruction
        
        IR转换成SSA形式的工作：
            为必要的变量添加PHI函数
            修改变量的定值和使用，为变量添加版本信息
        SSA需要改造原IR
        ART中，SSA的改造是在优化器将基本块中的dex指令转换为HInstruction（art中的IR）时实施的
        dex指令中变量的实际载体是寄存器
        ART的IR统称为HInstruction，HInstruction被定义为一个类
        构造整理完CFG之后，ART优化器下一步工作就是遍历基本块，然后将其包含的dex字节码转换成对应HInstruction
        ART中共有13种优化类：
            识别Instrinsics方法、处理常量折叠、消除CFG中无效的基本块、
            冗余代码消除、循环不变量外提、函数调用的分发方式、函数调用内联化、
            消除不必要的HBoundsCheck IR、消除不必要的数据存取指令等


#### ART中的IR--HInstruction

    ART IR的定义（包括CFG、基本块相关操作）都定义在 nodes.h和 nodes.cc 中
    ART中的IR：
        IR的基类为 HInstruction
        IR命名为 HXyz形式，Xyz为具体指令的名称或代表抽象操作的名称，如：HAdd、HSub、HInvoke
        具体IR：不是抽象类，无虚函数，IR代表明确的操作
        抽象IR：二元操作 HBinaryOperation、一元操作 HUnaryOperation
    IR之间的关系：
        dex指令之间是一种简单的、线性链接关系
        线性关系，一个基本块中的所有HInstruction存在线性链接关系，使用链表存储
        使用和被使用关系，一些IR需要使用别的IR，被使用的IR需要记住自己被谁使用了（被一个或多个使用）
    从dex指令转换得到ART IR：
        IR对象初始化，由 InstructionBuilder 类的 Build函数完成
        
        
#### 寄存器分配
    
    寄存器分配属于优化工作的一部分，在优化的最后阶段执行
    Register Allocation，ATR IR经过多轮优化后，下一步就要考虑寄存器的分配和指派（Register Assignment）问题
    dex指令码和 HInstruction 操作的都是虚拟寄存器，虚拟寄存器无个数限制，而物理寄存器只有有限个寄存器
    物理寄存器不够时，优化器将物理寄存器中原来的数据先保存到内存（溢出，spilling），给别的指令腾出寄存器；
    用完之后，需要将内存里保存的数据重新加载到物理寄存器中（填充，filling），多次重复上述情况会影响程序运行效率，所以需要一个良好的寄存器分配方案
    寄存器指派是指为那些已确定需要放在寄存器中的变量选择合适的寄存器
    分配方案既要考虑分配算法的执行时间，又要考虑分配后得到的代码执行效率（spilling次数越少，运行效率越高）
    分配算法：
        图着色法（Graph Coloring）
        线性扫描寄存器分配法（Linear Scan Register Allocation，LSRA）
    全局寄存器分配：针对CFG里多个基本块开展
    局部寄存器分配：针对单个基本块开展
    
    LSRA介绍：
        ART使用基于SSA形式的LSRA
        IR编号：LSRA中，CFG中每一条IR都有一个编号，编号顺序每次递增2（编译器可能会自动插入IR，编号为奇数）
        计算Lifetime Interval：对虚拟寄存器的Lifetime Interval是[i,j]，i、j是IR编号
        SSA形式IR的Lifetime Interval分析
    LSRA算法主要步骤：
        线性化CFG，对基本块中的IR进行编号
        计算虚拟寄存器的 lifetime interval
        进行线性扫描，与此同时，各 interval 的寄存器分配信息将确定
        Resolve 解决冲突，同时去 SSA 化
    
    
#### 机器码生成
    
    ART中机器码生成是通过调用代码生成器（CodeGenerator）的Compile函数完成的
    创建栈帧
    遍历基本块
    生成机器指令 SlowPathCode类
    
    Dex/Java字节码编译成目标机器码，它的编译和运行依赖操作系统和具体的虚拟机实现
    得到的机器码在运行过程中离不开虚拟机的管控（比如：GC对对象做标记）